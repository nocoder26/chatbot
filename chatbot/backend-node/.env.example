# === DATABASE ===
DATABASE_URL="postgresql://user:password@localhost:5432/izana?schema=public"

# === JWT ===
JWT_SECRET=your-super-secret-jwt-key-min-32-chars
JWT_VERIFY_EXPIRY=10m
JWT_ACCESS_EXPIRY=7d

# === LLM (Provider-agnostic: groq, ollama, or any OpenAI-compatible API) ===
GROQ_API_KEY=your-groq-api-key
LLM_PROVIDER=groq
# LLM_BASE_URL=  (auto-set per provider; override for custom endpoints)
# LLM_API_KEY=   (falls back to GROQ_API_KEY)
LLM_MODEL=llama-3.3-70b-versatile

# === Embeddings (local open-source model, no API needed) ===
EMBEDDING_MODEL=Xenova/bge-large-en-v1.5
EMBEDDING_DIMS=1024

# === Pinecone Vector DB (1024 dimensions) ===
PINECONE_API_KEY=your-pinecone-api-key
# Knowledge base: answers sourced from here (5 variants → search → 85% match threshold)
PINECONE_KB_INDEX=reproductive-health-zd6yy0f
PINECONE_KB_HOST=https://reproductive-health-zd6yy0f.svc.aped-4627-b74a.pinecone.io
# User data: user queries and responses stored here (GDPR: hashed userId in metadata)
PINECONE_USERDATA_INDEX=userdata-zd6yy0f
PINECONE_USERDATA_HOST=https://userdata-zd6yy0f.svc.aped-4627-b74a.pinecone.io
PINECONE_BLOODWORK_INDEX=bloodwork
PINECONE_BLOODWORK_HOST=https://bloodwork-zd6yy0f.svc.aped-4627-b74a.pinecone.io
# Set to true on Railway (free tier) to skip local model loading
DISABLE_LOCAL_EMBEDDINGS=false
# Cohere: embeddings (when local disabled) and chat. Set for Cohere-only; never commit the key.
# COHERE_API_KEY=
# COHERE_CHAT_MODEL=command-r-plus-08-2024
# COHERE_EMBED_TIMEOUT_MS=15000  (embed request timeout; avoid 502 from hanging)
# LLM_MAX_TOKENS=1024
# LLM_CHAT_TIMEOUT_MS=50000  (chat/bloodwork LLM timeout; keep under gateway timeout to avoid 502)
# Semantic cache: max entries and TTL in ms (default 500 entries, 5 min)
# SEMANTIC_CACHE_MAX_SIZE=500
# SEMANTIC_CACHE_TTL_MS=300000

# === Retrieval pipeline (dense KB + BM25 fusion + sufficiency) ===
RAG_KB_TOP_K=30
RAG_TOP_K_CONTEXT=6
SUFFICIENCY_TOP_THRESHOLD=0.5
SUFFICIENCY_DROP_OFF_RATIO=0.6

# === Chat topic filter (reproductive health only) ===
# Only treat as off-topic when classifier confidence >= this (0-1). Default 0.5.
# TOPIC_FILTER_CONFIDENCE_THRESHOLD=0.5

# === CORS ===
VERCEL_APP_URL=https://your-app.vercel.app
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001

# === Push Notifications (PWA) ===
# Generate with: npx web-push generate-vapid-keys
VAPID_PUBLIC_KEY=
VAPID_PRIVATE_KEY=
VAPID_SUBJECT=mailto:admin@izana.ai

# === GDPR / Encryption ===
ENCRYPTION_MASTER_KEY=generate-with-openssl-rand-hex-32
CONSENT_VERSION=1.0
DP_EPSILON=1.0
K_ANONYMITY_THRESHOLD=10
TIER2_RETENTION_MONTHS=18
